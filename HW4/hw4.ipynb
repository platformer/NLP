{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK WordNet Exploration\n",
    "\n",
    "**Author:** Andrew Sen\n",
    "\n",
    "**Date:** 9/25/2022\n",
    "\n",
    "WordNet is a hierarchical organization of nouns, verbs, adjectives, and adverbs. For each word, WordNet includes information about definitions of the word, synonym sets called synsets, usage examples, and relations to other words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synsets for Nouns\n",
    "\n",
    "I will use the noun \"game\" and explore its associated synsets with WordNet. First, I will output all synsets for \"game.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('game.n.01'),\n",
       " Synset('game.n.02'),\n",
       " Synset('game.n.03'),\n",
       " Synset('game.n.04'),\n",
       " Synset('game.n.05'),\n",
       " Synset('game.n.06'),\n",
       " Synset('game.n.07'),\n",
       " Synset('plot.n.01'),\n",
       " Synset('game.n.09'),\n",
       " Synset('game.n.10'),\n",
       " Synset('game.n.11'),\n",
       " Synset('bet_on.v.01'),\n",
       " Synset('crippled.s.01'),\n",
       " Synset('game.s.02')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "wn.synsets('game')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the first synset in the list, I will output its definition, usage examples, and lemmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definition:\n",
      "a contest with rules to determine a winner\n",
      "\n",
      "Usage Examples:\n",
      "['you need four people to play this game']\n",
      "\n",
      "Lemmas:\n",
      "[Lemma('game.n.01.game')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "game = wn.synset('game.n.01')\n",
    "# extracting definitions\n",
    "print(f'Definition:\\n{game.definition()}\\n')\n",
    "# extracting usage examples\n",
    "print(f'Usage Examples:\\n{game.examples()}\\n')\n",
    "# extracting lemmas\n",
    "print(f'Lemmas:\\n{game.lemmas()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use WordNet to traverse up a word's hierarchy of hypernyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('activity.n.01')\n",
      "Synset('act.n.02')\n",
      "Synset('event.n.01')\n",
      "Synset('psychological_feature.n.01')\n",
      "Synset('abstraction.n.06')\n",
      "Synset('entity.n.01')\n"
     ]
    }
   ],
   "source": [
    "# extracting hypernyms of 'game'\n",
    "hyp = game.hypernyms()[0]\n",
    "while hyp:\n",
    "    print(hyp)\n",
    "    if hyp.hypernyms():\n",
    "        hyp = hyp.hypernyms()[0]\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see with this example, WordNet has a topmost hypernym for nouns in the form of the 'entity' synset. Under this system, all other nouns are a hyponym of 'entity.' As we will see, this is unlike how verbs are organized in WordNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synsets for Verbs\n",
    "\n",
    "As we did for the noun 'game,' we will do the same to explore the synsets of the verb 'play.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('play.n.01'),\n",
       " Synset('play.n.02'),\n",
       " Synset('play.n.03'),\n",
       " Synset('maneuver.n.03'),\n",
       " Synset('play.n.05'),\n",
       " Synset('play.n.06'),\n",
       " Synset('bid.n.02'),\n",
       " Synset('play.n.08'),\n",
       " Synset('playing_period.n.01'),\n",
       " Synset('free_rein.n.01'),\n",
       " Synset('shimmer.n.01'),\n",
       " Synset('fun.n.02'),\n",
       " Synset('looseness.n.05'),\n",
       " Synset('play.n.14'),\n",
       " Synset('turn.n.03'),\n",
       " Synset('gambling.n.01'),\n",
       " Synset('play.n.17'),\n",
       " Synset('play.v.01'),\n",
       " Synset('play.v.02'),\n",
       " Synset('play.v.03'),\n",
       " Synset('act.v.03'),\n",
       " Synset('play.v.05'),\n",
       " Synset('play.v.06'),\n",
       " Synset('play.v.07'),\n",
       " Synset('act.v.05'),\n",
       " Synset('play.v.09'),\n",
       " Synset('play.v.10'),\n",
       " Synset('play.v.11'),\n",
       " Synset('play.v.12'),\n",
       " Synset('play.v.13'),\n",
       " Synset('play.v.14'),\n",
       " Synset('play.v.15'),\n",
       " Synset('play.v.16'),\n",
       " Synset('play.v.17'),\n",
       " Synset('play.v.18'),\n",
       " Synset('toy.v.02'),\n",
       " Synset('play.v.20'),\n",
       " Synset('dally.v.04'),\n",
       " Synset('play.v.22'),\n",
       " Synset('dally.v.01'),\n",
       " Synset('play.v.24'),\n",
       " Synset('act.v.10'),\n",
       " Synset('play.v.26'),\n",
       " Synset('bring.v.03'),\n",
       " Synset('play.v.28'),\n",
       " Synset('play.v.29'),\n",
       " Synset('bet.v.02'),\n",
       " Synset('play.v.31'),\n",
       " Synset('play.v.32'),\n",
       " Synset('play.v.33'),\n",
       " Synset('meet.v.10'),\n",
       " Synset('play.v.35')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('play')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will select the first verb synset in the list and extract its definition, usage examples, and lemmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definition:\n",
      "participate in games or sport\n",
      "\n",
      "Usage Examples:\n",
      "['We played hockey all afternoon', 'play cards', 'Pele played for the Brazilian teams in many important matches']\n",
      "\n",
      "Lemmas:\n",
      "[Lemma('play.v.01.play')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "play = wn.synset('play.v.01')\n",
    "# extracting definitions\n",
    "print(f'Definition:\\n{play.definition()}\\n')\n",
    "# extracting usage examples\n",
    "print(f'Usage Examples:\\n{play.examples()}\\n')\n",
    "# extracting lemmas\n",
    "print(f'Lemmas:\\n{play.lemmas()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also traverse the heirarchy of hypernyms for a given verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('compete.v.01')\n"
     ]
    }
   ],
   "source": [
    "# extracting hypernyms of 'play'\n",
    "hyp = play.hypernyms()[0]\n",
    "while hyp:\n",
    "    print(hyp)\n",
    "    if hyp.hypernyms():\n",
    "        hyp2 = hyp.hypernyms()[0]\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the topmost hypernym for 'play' is 'compete.' This cannot be a general hypernym for all verbs. This shows that, unlike with nouns, WordNet does not categorize all verbs as being hyponyms to some universal umbrella verb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `morphy()` function returns the base form of a word. We can use it to confirm that certain words are just different forms of the word 'play.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: base\n",
      "--------\n",
      "played: play\n",
      "playing: playing\n",
      "plays: play\n",
      "player: player\n"
     ]
    }
   ],
   "source": [
    "forms = ['played', 'playing', 'plays', 'player']\n",
    "print(\"word: base\\n--------\")\n",
    "for f in forms:\n",
    "    print(f'{f}: {wn.morphy(f)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity and Word Sense Disambiguation\n",
    "\n",
    "WordNet includes the Wu-Palmer algorithm for determining the similarity between two words. NLTK also has an implementation of the Lesk algorithm for determining which definition of a word is being used in a given sentence. To test both, I will use two different forms of the word 'punch.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I will output the definitions of each synset of 'punch' to pick the right synsets to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "punch.n.01: (boxing) a blow with the fist\n",
      "punch.n.02: an iced mixed drink usually containing alcohol and prepared for multiple servings; normally served in a punch bowl\n",
      "punch.n.03: a tool for making holes or indentations\n",
      "punch.v.01: deliver a quick blow to\n",
      "punch.v.02: drive forcibly as if by a punch\n",
      "punch.v.03: make a hole into or between, as for ease of separation\n"
     ]
    }
   ],
   "source": [
    "for ss in wn.synsets('punch'):\n",
    "    print(ss.name() + ': ' + ss.definition())\n",
    "\n",
    "# Lesk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use `punch.n.02` and `punch.v.01` for this example. Now let's use Wu-Palmer to determine their similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13333333333333333"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punch_hit = wn.synset('punch.v.01')\n",
    "punch_drink = wn.synset('punch.n.02')\n",
    "\n",
    "wn.wup_similarity(punch_hit, punch_drink)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that Wu-Palmer gave the two senses of 'punch' a low similarity score, which is to be expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use Lesk to disambiguate the use of 'punch' in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('punch.n.02')\n",
      "Synset('punch.v.02')\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "\n",
    "sentence = ['I', 'walked', 'to', 'the', 'table',\n",
    "            'and', 'grabbed', 'some', 'punch']\n",
    "print(lesk(sentence, 'punch'))\n",
    "\n",
    "sentence2 = ['I', 'wanted', 'to', 'punch', 'him']\n",
    "print(lesk(sentence2, 'punch'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that Lesk was able to correctly disambiguate the first sentence. The disambiguation suggested for the second sentence was not what I expected, but the definitions of `punch.v.01` and `punch.v.02` are similar nonetheless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SentiWordNet\n",
    "\n",
    "SentiWordNet is a tool for programmatically determining the sentiment of a piece of text. Given some text, it will assign scores in positivity, negativity, and objectivity.\n",
    "\n",
    "For this example, I will use the word 'attack.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<attack.n.01: PosScore=0.0 NegScore=0.0>\n",
      "<attack.n.02: PosScore=0.0 NegScore=0.0>\n",
      "<fire.n.09: PosScore=0.125 NegScore=0.5>\n",
      "<approach.n.01: PosScore=0.0 NegScore=0.0>\n",
      "<attack.n.05: PosScore=0.0 NegScore=0.0>\n",
      "<attack.n.06: PosScore=0.0 NegScore=0.0>\n",
      "<attack.n.07: PosScore=0.0 NegScore=0.25>\n",
      "<attack.n.08: PosScore=0.0 NegScore=0.125>\n",
      "<attack.n.09: PosScore=0.25 NegScore=0.125>\n",
      "<attack.v.01: PosScore=0.0 NegScore=0.0>\n",
      "<attack.v.02: PosScore=0.0 NegScore=0.0>\n",
      "<attack.v.03: PosScore=0.0 NegScore=0.5>\n",
      "<assail.v.01: PosScore=0.0 NegScore=0.375>\n",
      "<attack.v.05: PosScore=0.0 NegScore=0.0>\n",
      "<attack.v.06: PosScore=0.0 NegScore=0.0>\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "for ss in swn.senti_synsets('attack'):\n",
    "    print(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will make up a sentence and find the polarity of each word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: <one.s.01: PosScore=0.0 NegScore=0.25>\n",
      "really: <very.r.01: PosScore=0.25 NegScore=0.25>\n",
      "hate: <hate.v.01: PosScore=0.0 NegScore=0.75>\n",
      "drinking: <drink.n.02: PosScore=0.0 NegScore=0.0>\n",
      "iced: <ice.v.03: PosScore=0.0 NegScore=0.0>\n",
      "coffee: <coffee_bean.n.01: PosScore=0.0 NegScore=0.0>\n"
     ]
    }
   ],
   "source": [
    "sentence = 'I really hate drinking iced coffee'\n",
    "tokens = sentence.split()\n",
    "\n",
    "for token in tokens:\n",
    "    ss = lesk(tokens, token) # use Lesk to get best synset\n",
    "    print(f'{token}: {swn.senti_synset(ss.name())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the word 'I' interestingly has a slightly negative polarity. The word 'really' has equal positive and negative polarities, which makes sense because it can precede either a positive or negative word. 'Hate' is very negative as to be expected, and the remaining words have no polarity.\n",
    "\n",
    "In a real NLP application, it would be useful to have these sentiment scores because it gives extra information about the meaning of a text. Sentiment information could be used as extra factors in a given language model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocations\n",
    "\n",
    "A collocation is a group of words that, when put together, refer to a particular thing or action, and the same effect is not achieved if one of the words is replaced with a synonym. An example would be the term 'fast food.' 'Fast food' means something very particular, and saying 'quick food' either sounds wrong or is referring to a different concept altogether.\n",
    "\n",
    "We will list the collocations found in one of NLTK's built-in texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; years ago; four years; Federal\n",
      "Government; General Government; American people; Vice President; God\n",
      "bless; Chief Justice; one another; fellow Americans; Old World;\n",
      "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
      "tribes; public debt; foreign nations\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import text4\n",
    "text4.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now calculate the mutual information of the collocation 'Federal Government.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(Federal Government) =  0.38095238095238093\n",
      "p(Federal) =  0.7738095238095238\n",
      "p(Government) =  4.023809523809524\n",
      "pmi =  -3.0309298265318785\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "text = ' '.join(text4.tokens)\n",
    "vocab = len(set(text))\n",
    "fg = text.count('Federal Government') / vocab\n",
    "print(\"p(Federal Government) = \", fg)\n",
    "f = text.count('Federal') / vocab\n",
    "print(\"p(Federal) = \", f)\n",
    "g = text.count('Government') / vocab\n",
    "print('p(Government) = ', g)\n",
    "pmi = math.log2(fg / (f * g))\n",
    "print('pmi = ', pmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A negative pmi indicates that 'Federal Government' is not likely to be a collocation in this text. Since NLTK did consider it a collocation, we can assume that NLTK uses some other means of determining whether or not a phrase is a collocation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2f6d2e506039e31c138a83804915592f1c7545f0a7c0fb6e56ae42501e56b8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
