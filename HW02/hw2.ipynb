{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two things I learned about Text objects:\n",
    "*   Text objects support slices\n",
    "*   The name attribute of a Text object is either the first 8 words or, if there is a square bracket in the first 20 words, the words contained in the square brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Moby', 'Dick', 'by', 'Herman', 'Melville', '1851', ']', 'ETYMOLOGY', '.', '(', 'Supplied', 'by', 'a', 'Late', 'Consumptive', 'Usher', 'to', 'a', 'Grammar']\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import text1\n",
    "print(text1.tokens[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code imports one of NLTK's built in texts and prints the first 20 tokens of that text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 455 matches:\n",
      " shall slay the dragon that is in the sea .\" -- ISAIAH \" And what thing soever \n",
      " S PLUTARCH ' S MORALS . \" The Indian Sea breedeth the most and the biggest fis\n",
      "cely had we proceeded two days on the sea , when about sunrise a great many Wha\n",
      "many Whales and other monsters of the sea , appeared . Among the former , one w\n",
      " waves on all sides , and beating the sea before him into a foam .\" -- TOOKE ' \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(text1.concordance('sea', lines=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code takes the imported Text object and prints 5 lines that include the word 'sea' along with the surrounding text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count() function for Text objects calls count() on the instance token list. This is the same as Pythonâ€™s built in count() for lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text1.count():        433\n",
      "text1.tokens.count(): 433\n"
     ]
    }
   ],
   "source": [
    "print(f'text1.count():        {text1.count(\"sea\")}')\n",
    "print(f'text1.tokens.count(): {text1.tokens.count(\"sea\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code prints the result of using the Text object count() function and the built in count() function for lists. The results of both are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following uses an excerpt found on natethesnake.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['By', 'the', 'end', 'of', 'the', 'day', ',', 'he', 'starts', 'getting']\n"
     ]
    }
   ],
   "source": [
    "raw_text = \"By the end of the day, he starts getting worried. He figures he's been walking at least three miles an hour, according to his watch for over ten hours. That means that if his estimate was right, he should be close to the town. Unfortunately, he doesn't recognize any of this. He had to cross a dry creek bed a mile or two back, and he doesn't remember coming through it in the SUV.\"\n",
    "tokens = nltk.word_tokenize(raw_text)\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code tokenizes the provided text and prints the first 10 tokens of the provided text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['By the end of the day, he starts getting worried.', \"He figures he's been walking at least three miles an hour, according to his watch for over ten hours.\", 'That means that if his estimate was right, he should be close to the town.', \"Unfortunately, he doesn't recognize any of this.\", \"He had to cross a dry creek bed a mile or two back, and he doesn't remember coming through it in the SUV.\"]\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(raw_text)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code splits the text into its component sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['by', 'the', 'end', 'of', 'the', 'day', ',', 'he', 'start', 'get', 'worri', '.', 'he', 'figur', 'he', \"'s\", 'been', 'walk', 'at', 'least', 'three', 'mile', 'an', 'hour', ',', 'accord', 'to', 'hi', 'watch', 'for', 'over', 'ten', 'hour', '.', 'that', 'mean', 'that', 'if', 'hi', 'estim', 'wa', 'right', ',', 'he', 'should', 'be', 'close', 'to', 'the', 'town', '.', 'unfortun', ',', 'he', 'doe', \"n't\", 'recogn', 'ani', 'of', 'thi', '.', 'he', 'had', 'to', 'cross', 'a', 'dri', 'creek', 'bed', 'a', 'mile', 'or', 'two', 'back', ',', 'and', 'he', 'doe', \"n't\", 'rememb', 'come', 'through', 'it', 'in', 'the', 'suv', '.']\n"
     ]
    }
   ],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()\n",
    "print([stemmer.stem(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code uses NLTK's PorterStemmer to print the tokens in their stemmed forms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differences between stemming and lemmatizing (stem - lemma):\n",
    "*   by - By\n",
    "*   get - getting\n",
    "*   he - He\n",
    "*   figur - figure\n",
    "*   walk - walking\n",
    "*   accord - according\n",
    "*   hi - his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['By', 'the', 'end', 'of', 'the', 'day', ',', 'he', 'start', 'getting', 'worried', '.', 'He', 'figure', 'he', \"'s\", 'been', 'walking', 'at', 'least', 'three', 'mile', 'an', 'hour', ',', 'according', 'to', 'his', 'watch', 'for', 'over', 'ten', 'hour', '.', 'That', 'mean', 'that', 'if', 'his', 'estimate', 'wa', 'right', ',', 'he', 'should', 'be', 'close', 'to', 'the', 'town', '.', 'Unfortunately', ',', 'he', 'doe', \"n't\", 'recognize', 'any', 'of', 'this', '.', 'He', 'had', 'to', 'cross', 'a', 'dry', 'creek', 'bed', 'a', 'mile', 'or', 'two', 'back', ',', 'and', 'he', 'doe', \"n't\", 'remember', 'coming', 'through', 'it', 'in', 'the', 'SUV', '.']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "print([lemmatizer.lemmatize(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code uses NLTK's WordNetLemmatizer to print the tokens in lemmatized forms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the NLTK library provides a lot of useful functionalities for processing bodies of text. It is far easier to use functions from NLTK than it is to try to handwrite functions that achieve similar goals. I think the code quality of NLTK is very good. It is easy to read and understand, and it is well-documented. In future projects, I can use NLTK to process a body of text before feeding it to some NLP application, as it is easier to process tokenized and lemmatized text. NLTK can also provide metrics and statistical information about a body of text, which is also useful for text processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2f6d2e506039e31c138a83804915592f1c7545f0a7c0fb6e56ae42501e56b8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
