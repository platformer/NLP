{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author Attribution\n",
    "\n",
    "**Author:** Andrew Sen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Manipulating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HAMILTON                49\n",
       "MADISON                 15\n",
       "HAMILTON OR MADISON     11\n",
       "JAY                      5\n",
       "HAMILTON AND MADISON     3\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read data\n",
    "df = pd.read_csv('federalist.csv')\n",
    "df.author = df.author.astype('category')\n",
    "\n",
    "# print count by author\n",
    "df.author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions:\n",
      "X_train: (66,)\n",
      "y_train: (66,)\n",
      "X_test: (17,)\n",
      "y_test: (17,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting data into train/test\n",
    "X = df['text']\n",
    "y = df.author\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "print('Dimensions:')\n",
    "print(f'X_train: {str(X_train.shape)}')\n",
    "print(f'y_train: {str(y_train.shape)}')\n",
    "print(f'X_test: {str(X_test.shape)}')\n",
    "print(f'y_test: {str(y_test.shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dimensions:\n",
      "X_train: (66, 7876)\n",
      "X_test: (17, 7876)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# removing stopwords and performing tf-idf vectorization\n",
    "stopwords = set(stopwords.words('english'))\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "print('New dimensions:')\n",
    "print(f'X_train: {str(X_train_vectorized.shape)}')\n",
    "print(f'X_test: {str(X_test_vectorized.shape)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5882352941176471\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nb = BernoulliNB()\n",
    "nb.fit(X_train_vectorized, y_train)\n",
    "pred_nb = nb.predict(X_test_vectorized)\n",
    "print('Accuracy: ', accuracy_score(y_test, pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the results, we'll try different settings for the vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words=stopwords,\n",
    "    max_features=1000,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "nb2 = BernoulliNB()\n",
    "nb2.fit(X_train_vectorized, y_train)\n",
    "pred_nb2 = nb2.predict(X_test_vectorized)\n",
    "print('Accuracy: ', accuracy_score(y_test, pred_nb2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy greatly improved when we decreased the number of features and added bigrams to the model. This is likely because differences between different authors' writing styles become more pronounced when bigrams are considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5882352941176471\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# logistic regression with default settings\n",
    "lr1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('logreg', LogisticRegression()),\n",
    "])\n",
    "\n",
    "lr1.fit(X_train, y_train)\n",
    "pred_lr1 = lr1.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(y_test, pred_lr1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "# logistic regression with modified settings\n",
    "lr2 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('logreg', LogisticRegression(\n",
    "        multi_class='multinomial',\n",
    "        class_weight='balanced',\n",
    "        solver='lbfgs'\n",
    "    )),\n",
    "])\n",
    "\n",
    "lr2.fit(X_train, y_train)\n",
    "pred_lr2 = lr2.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(y_test, pred_lr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the two logistic regression models, the second performed far better. This is likely because setting the `class_weight` parameter to `balanced` allowed the model to adjust to the imbalanced frequencies of each author."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6470588235294118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nn1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('neuralnet', MLPClassifier(\n",
    "        solver='lbfgs',\n",
    "        hidden_layer_sizes=(15, 7),\n",
    "        random_state=1234,\n",
    "        max_iter=1000\n",
    "    )),\n",
    "])\n",
    "\n",
    "nn1.fit(X_train, y_train)\n",
    "pred_nn1 = nn1.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(y_test, pred_nn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7058823529411765\n"
     ]
    }
   ],
   "source": [
    "nn2 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        ngram_range=(1,2)\n",
    "    )),\n",
    "    ('neuralnet', MLPClassifier(\n",
    "        solver='lbfgs',\n",
    "        hidden_layer_sizes=(15, 7),\n",
    "        random_state=1234,\n",
    "        max_iter=1000\n",
    "    )),\n",
    "])\n",
    "\n",
    "nn2.fit(X_train, y_train)\n",
    "pred_nn2 = nn2.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(y_test, pred_nn2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7647058823529411\n"
     ]
    }
   ],
   "source": [
    "nn3 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        ngram_range=(1,2)\n",
    "    )),\n",
    "    ('neuralnet', MLPClassifier(\n",
    "        solver='lbfgs',\n",
    "        hidden_layer_sizes=(20, 15, 7),\n",
    "        random_state=1234,\n",
    "        max_iter=1000\n",
    "    )),\n",
    "])\n",
    "\n",
    "nn3.fit(X_train, y_train)\n",
    "pred_nn3 = nn3.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(y_test, pred_nn3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuracy I could get using neural networks was ~76%. Adding more layers would result in the accuracy decreasing due to overfit, and adjusting the number of nodes in each layer seems to have little effect. This makes logistic regression and Bernoulli Naive Bayes the far better performers in my testing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
